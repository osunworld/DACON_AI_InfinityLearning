{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyN42NTCmq9tJlhLmgOZaKdn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"91bZ1iB6qffl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751647136753,"user_tz":-540,"elapsed":17254,"user":{"displayName":"정태양","userId":"07065479975462546638"}},"outputId":"5773b2fa-3116-44c0-b464-a3a3607f572c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","\n","\n","# 베이스 경로 설정\n","BASE_DIR = '/content/drive/MyDrive/Dacon_FakeText/'\n"]},{"cell_type":"code","source":["!pip install iterative-stratification\n","!pip install pyarrow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDOVdsf1Y5k2","executionInfo":{"status":"ok","timestamp":1751647147191,"user_tz":-540,"elapsed":10433,"user":{"displayName":"정태양","userId":"07065479975462546638"}},"outputId":"476d7b74-af2a-40fb-f297-59cd8ac47353"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting iterative-stratification\n","  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.6.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\n","Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n","Installing collected packages: iterative-stratification\n","Successfully installed iterative-stratification-0.1.9\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import roc_auc_score\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","from tqdm import tqdm\n","import os\n","import gc"],"metadata":{"id":"SqkF_FooqqsC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. 설정값\n","n_splits = 5\n","batch_size = 512\n","epochs = 30\n","early_stopping_rounds = 3\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"bDdnuWkqqzda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. 데이터 로딩\n","X_train = np.load(BASE_DIR + 'data/embeddings/train_concat.npy').astype(np.float16)\n","train_meta = pd.read_csv(BASE_DIR + 'data/train_paragraph.csv')\n","\n","assert len(X_train) == len(train_meta), \"X_train과 train_meta의 길이가 다릅니다.\"\n","\n","\n","y_train = train_meta['generated'].values.astype(np.float32)\n","groups = train_meta['title'].values\n","\n","print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cCQGJr_q58B","executionInfo":{"status":"ok","timestamp":1751647261120,"user_tz":-540,"elapsed":24258,"user":{"displayName":"정태양","userId":"07065479975462546638"}},"outputId":"a2238f8c-bdf7-46f5-fea5-d8397b83e623"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (1226364, 775), y_train shape: (1226364,)\n"]}]},{"cell_type":"code","source":["# 3. PyTorch Dataset 클래스\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X  # np.float16\n","        self.y = y  # np.float32\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        x = torch.from_numpy(self.X[idx])\n","        y = torch.tensor(self.y[idx], dtype=torch.float32)\n","        return x, y"],"metadata":{"id":"qN7WlfmKrLoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QjhjYLn9Ay9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StratifiedGroupKFold:\n","    def __init__(self, n_splits=5, shuffle=True, random_state=None):\n","        self.n_splits = n_splits\n","        self.shuffle = shuffle\n","        self.random_state = random_state\n","\n","    def split(self, X, y, groups):\n","        # 그룹을 정수로 인코딩\n","        if not np.issubdtype(groups.dtype, np.number):\n","            groups = LabelEncoder().fit_transform(groups)\n","\n","        # 그룹별 인덱스 저장\n","        group_to_indices = {}\n","        for idx, g in enumerate(groups):\n","            group_to_indices.setdefault(g, []).append(idx)\n","\n","        unique_groups = np.array(list(group_to_indices.keys()))\n","        group_y = np.array([\n","            int(y[group_to_indices[g]].mean() >= 0.5) for g in unique_groups\n","        ])\n","\n","        skf = StratifiedKFold(\n","            n_splits=self.n_splits,\n","            shuffle=self.shuffle,\n","            random_state=self.random_state\n","        )\n","\n","        for group_train_idx, group_val_idx in skf.split(unique_groups, group_y):\n","            train_indices, val_indices = [], []\n","\n","            for gi in group_train_idx:\n","                train_indices.extend(group_to_indices[unique_groups[gi]])\n","            for gi in group_val_idx:\n","                val_indices.extend(group_to_indices[unique_groups[gi]])\n","\n","            yield np.array(train_indices), np.array(val_indices)"],"metadata":{"id":"JlkEQMEvSOAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. MLP 모델 클래스\n","class MLP(nn.Module):\n","    def __init__(self, input_dim):\n","        super(MLP, self).__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.4),\n","\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.4),\n","\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","\n","            nn.Linear(64,1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)"],"metadata":{"id":"PxbUe4CCspqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. GroupKFold + 학습 + 로그 저장\n","sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n","oof_preds = np.zeros(len(X_train))\n","\n","all_logs = []  # 전체 로그 저장용 리스트\n","y_train=y_train.astype(np.float32)\n","for fold, (train_idx, val_idx) in enumerate(sgkf.split(X_train, y_train, groups)):\n","    print(f'\\n=== Fold {fold+1}/{n_splits} 학습 시작 ===')\n","\n","    X_tr, y_tr = X_train[train_idx], y_train[train_idx]\n","    X_val, y_val = X_train[val_idx], y_train[val_idx]\n","\n","    train_dataset = CustomDataset(X_tr, y_tr)\n","    val_dataset = CustomDataset(X_val, y_val)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=2,pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=2,pin_memory=True)\n","\n","    model = MLP(input_dim=X_train.shape[1]).to(device)\n","    criterion = nn.BCELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer,\n","    mode='max',           # val_auc가 증가해야 하므로 'max'\n","    factor=0.5,           # lr을 절반으로 줄임\n","    patience=3,           # 3 epoch 동안 개선 없으면 감소\n","    verbose=True,\n","    min_lr=1e-6           # 최소 학습률 하한\n","    )\n","\n","\n","    best_auc = 0\n","    patience_counter = 0\n","    fold_log = []  # 이 fold의 epoch별 로그 저장용 리스트\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss = 0\n","        for xb, yb in train_loader:\n","            xb, yb = xb.to(device).float(), yb.to(device)\n","            optimizer.zero_grad()\n","            preds = model(xb)\n","            loss = criterion(preds, yb.view(-1,1))\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","\n","        # Validation\n","        model.eval()\n","        val_preds = []\n","        with torch.no_grad():\n","            for xb, _ in val_loader:\n","                xb = xb.to(device).float()\n","                pred = model(xb).squeeze()\n","                val_preds.extend(pred.cpu().numpy())\n","\n","        auc = roc_auc_score(y_val, val_preds)\n","        avg_train_loss = train_loss / len(train_loader)\n","\n","        print(f\"Fold {fold+1} | Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val AUC: {auc:.4f}\")\n","\n","        # LR Scheduler 업데이트\n","        scheduler.step(auc)\n","\n","        # 로그 저장\n","        fold_log.append({\n","            'fold': fold + 1,\n","            'epoch': epoch + 1,\n","            'train_loss': avg_train_loss,\n","            'val_auc': auc\n","        })\n","\n","        # Early Stopping\n","        if auc > best_auc:\n","            best_auc = auc\n","            patience_counter = 0\n","            torch.save(model.state_dict(), BASE_DIR + f'model/mlp_bce/mlp_fold{fold+1}.pt')\n","            print(f\"Fold {fold+1} 모델 저장 (Best AUC: {best_auc:.4f})\")\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= early_stopping_rounds:\n","                print(f\"Early Stopping (patience {early_stopping_rounds} 도달)\")\n","                break\n","\n","    # Fold별 로그 저장\n","    all_logs.extend(fold_log)\n","\n","    # Fold OOF\n","    oof_preds[val_idx] = val_preds\n","\n","    del model, train_loader, val_loader, train_dataset, val_dataset\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n"],"metadata":{"id":"A30Y75EXrLlE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751647977600,"user_tz":-540,"elapsed":716438,"user":{"displayName":"정태양","userId":"07065479975462546638"}},"outputId":"49642fc1-e7bc-47c9-a177-fb5e56a53e49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1/5 학습 시작 ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 1 | Epoch 1 | Train Loss: 0.2461 | Val AUC: 0.6958\n","✅ Fold 1 모델 저장 (Best AUC: 0.6958)\n","Fold 1 | Epoch 2 | Train Loss: 0.2277 | Val AUC: 0.7024\n","✅ Fold 1 모델 저장 (Best AUC: 0.7024)\n","Fold 1 | Epoch 3 | Train Loss: 0.2247 | Val AUC: 0.7024\n","Fold 1 | Epoch 4 | Train Loss: 0.2224 | Val AUC: 0.7062\n","✅ Fold 1 모델 저장 (Best AUC: 0.7062)\n","Fold 1 | Epoch 5 | Train Loss: 0.2202 | Val AUC: 0.7097\n","✅ Fold 1 모델 저장 (Best AUC: 0.7097)\n","Fold 1 | Epoch 6 | Train Loss: 0.2181 | Val AUC: 0.7095\n","Fold 1 | Epoch 7 | Train Loss: 0.2167 | Val AUC: 0.7099\n","✅ Fold 1 모델 저장 (Best AUC: 0.7099)\n","Fold 1 | Epoch 8 | Train Loss: 0.2147 | Val AUC: 0.7104\n","✅ Fold 1 모델 저장 (Best AUC: 0.7104)\n","Fold 1 | Epoch 9 | Train Loss: 0.2134 | Val AUC: 0.7094\n","Fold 1 | Epoch 10 | Train Loss: 0.2113 | Val AUC: 0.7123\n","✅ Fold 1 모델 저장 (Best AUC: 0.7123)\n","Fold 1 | Epoch 11 | Train Loss: 0.2099 | Val AUC: 0.7088\n","Fold 1 | Epoch 12 | Train Loss: 0.2086 | Val AUC: 0.7107\n","Fold 1 | Epoch 13 | Train Loss: 0.2066 | Val AUC: 0.7083\n","❌ Early Stopping (patience 3 도달)\n","\n","=== Fold 2/5 학습 시작 ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 2 | Epoch 1 | Train Loss: 0.2474 | Val AUC: 0.6939\n","✅ Fold 2 모델 저장 (Best AUC: 0.6939)\n","Fold 2 | Epoch 2 | Train Loss: 0.2287 | Val AUC: 0.6975\n","✅ Fold 2 모델 저장 (Best AUC: 0.6975)\n","Fold 2 | Epoch 3 | Train Loss: 0.2257 | Val AUC: 0.6988\n","✅ Fold 2 모델 저장 (Best AUC: 0.6988)\n","Fold 2 | Epoch 4 | Train Loss: 0.2235 | Val AUC: 0.7025\n","✅ Fold 2 모델 저장 (Best AUC: 0.7025)\n","Fold 2 | Epoch 5 | Train Loss: 0.2215 | Val AUC: 0.7041\n","✅ Fold 2 모델 저장 (Best AUC: 0.7041)\n","Fold 2 | Epoch 6 | Train Loss: 0.2197 | Val AUC: 0.7025\n","Fold 2 | Epoch 7 | Train Loss: 0.2179 | Val AUC: 0.7055\n","✅ Fold 2 모델 저장 (Best AUC: 0.7055)\n","Fold 2 | Epoch 8 | Train Loss: 0.2159 | Val AUC: 0.7046\n","Fold 2 | Epoch 9 | Train Loss: 0.2142 | Val AUC: 0.7063\n","✅ Fold 2 모델 저장 (Best AUC: 0.7063)\n","Fold 2 | Epoch 10 | Train Loss: 0.2128 | Val AUC: 0.7016\n","Fold 2 | Epoch 11 | Train Loss: 0.2111 | Val AUC: 0.7024\n","Fold 2 | Epoch 12 | Train Loss: 0.2094 | Val AUC: 0.7095\n","✅ Fold 2 모델 저장 (Best AUC: 0.7095)\n","Fold 2 | Epoch 13 | Train Loss: 0.2079 | Val AUC: 0.7031\n","Fold 2 | Epoch 14 | Train Loss: 0.2062 | Val AUC: 0.7016\n","Fold 2 | Epoch 15 | Train Loss: 0.2045 | Val AUC: 0.7027\n","❌ Early Stopping (patience 3 도달)\n","\n","=== Fold 3/5 학습 시작 ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 3 | Epoch 1 | Train Loss: 0.2476 | Val AUC: 0.7001\n","✅ Fold 3 모델 저장 (Best AUC: 0.7001)\n","Fold 3 | Epoch 2 | Train Loss: 0.2301 | Val AUC: 0.7059\n","✅ Fold 3 모델 저장 (Best AUC: 0.7059)\n","Fold 3 | Epoch 3 | Train Loss: 0.2265 | Val AUC: 0.7059\n","Fold 3 | Epoch 4 | Train Loss: 0.2246 | Val AUC: 0.7124\n","✅ Fold 3 모델 저장 (Best AUC: 0.7124)\n","Fold 3 | Epoch 5 | Train Loss: 0.2227 | Val AUC: 0.7109\n","Fold 3 | Epoch 6 | Train Loss: 0.2209 | Val AUC: 0.7124\n","Fold 3 | Epoch 7 | Train Loss: 0.2192 | Val AUC: 0.7166\n","✅ Fold 3 모델 저장 (Best AUC: 0.7166)\n","Fold 3 | Epoch 8 | Train Loss: 0.2174 | Val AUC: 0.7133\n","Fold 3 | Epoch 9 | Train Loss: 0.2160 | Val AUC: 0.7080\n","Fold 3 | Epoch 10 | Train Loss: 0.2145 | Val AUC: 0.7118\n","❌ Early Stopping (patience 3 도달)\n","\n","=== Fold 4/5 학습 시작 ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 4 | Epoch 1 | Train Loss: 0.2460 | Val AUC: 0.7011\n","✅ Fold 4 모델 저장 (Best AUC: 0.7011)\n","Fold 4 | Epoch 2 | Train Loss: 0.2282 | Val AUC: 0.7091\n","✅ Fold 4 모델 저장 (Best AUC: 0.7091)\n","Fold 4 | Epoch 3 | Train Loss: 0.2250 | Val AUC: 0.6995\n","Fold 4 | Epoch 4 | Train Loss: 0.2229 | Val AUC: 0.7028\n","Fold 4 | Epoch 5 | Train Loss: 0.2210 | Val AUC: 0.7082\n","❌ Early Stopping (patience 3 도달)\n","\n","=== Fold 5/5 학습 시작 ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fold 5 | Epoch 1 | Train Loss: 0.2440 | Val AUC: 0.7029\n","✅ Fold 5 모델 저장 (Best AUC: 0.7029)\n","Fold 5 | Epoch 2 | Train Loss: 0.2269 | Val AUC: 0.6996\n","Fold 5 | Epoch 3 | Train Loss: 0.2239 | Val AUC: 0.7073\n","✅ Fold 5 모델 저장 (Best AUC: 0.7073)\n","Fold 5 | Epoch 4 | Train Loss: 0.2218 | Val AUC: 0.7092\n","✅ Fold 5 모델 저장 (Best AUC: 0.7092)\n","Fold 5 | Epoch 5 | Train Loss: 0.2198 | Val AUC: 0.7100\n","✅ Fold 5 모델 저장 (Best AUC: 0.7100)\n","Fold 5 | Epoch 6 | Train Loss: 0.2185 | Val AUC: 0.7157\n","✅ Fold 5 모델 저장 (Best AUC: 0.7157)\n","Fold 5 | Epoch 7 | Train Loss: 0.2167 | Val AUC: 0.7180\n","✅ Fold 5 모델 저장 (Best AUC: 0.7180)\n","Fold 5 | Epoch 8 | Train Loss: 0.2148 | Val AUC: 0.7135\n","Fold 5 | Epoch 9 | Train Loss: 0.2133 | Val AUC: 0.7137\n","Fold 5 | Epoch 10 | Train Loss: 0.2118 | Val AUC: 0.7133\n","❌ Early Stopping (patience 3 도달)\n"]}]},{"cell_type":"code","source":["# 6. 전체 OOF AUC\n","final_auc = roc_auc_score(y_train, oof_preds)\n","print(f\"\\n전체 OOF AUC: {final_auc:.4f}\")\n","\n","# 6-1. 전체 OOF 결과를 로그에 추가\n","log_df = pd.DataFrame(all_logs)\n","log_df = pd.concat([\n","    log_df,\n","    pd.DataFrame([{\n","        'fold': 0,\n","        'epoch': 0,\n","        'train_loss': np.nan,\n","        'val_auc': final_auc\n","    }])\n","], ignore_index=True)\n","\n","# 7. 최종 로그 CSV 저장\n","log_df.to_csv(BASE_DIR + 'logs/deep_mlp_training_log_5.csv', index=False, encoding='utf-8')\n","print(f\"전체 학습 로그 저장 완료: {BASE_DIR}logs/deep_mlp_training_log_1.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiUuVdbLrLiN","executionInfo":{"status":"ok","timestamp":1751647978403,"user_tz":-540,"elapsed":801,"user":{"displayName":"정태양","userId":"07065479975462546638"}},"outputId":"ae3e96b3-0033-4ef1-8f3b-ee23b78145ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","✅ 전체 OOF AUC: 0.7039\n","✅ 전체 학습 로그 저장 완료: /content/drive/MyDrive/Dacon_FakeText/logs/deep_mlp_training_log_1.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pIELUIZj11Um"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EZsFGhDYFIxW"},"execution_count":null,"outputs":[]}]}